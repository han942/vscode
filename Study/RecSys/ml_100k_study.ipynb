{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie-Lens 100k Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  ratings  timestamp\n",
       "0     196      242        3  881250949\n",
       "1     186      302        3  891717742\n",
       "2      22      377        1  878887116\n",
       "3     244       51        2  880606923\n",
       "4     166      346        1  886397596"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/han942/vscode/refs/heads/main/datafile/Recsys/ml-100k/u.data',sep='\\t',\n",
    "                   names=['userID','movieID','ratings','timestamp'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unknown',\n",
       " 'Action',\n",
       " 'Adventure',\n",
       " 'Animation',\n",
       " \"Children's\",\n",
       " 'Comedy',\n",
       " 'Crime',\n",
       " 'Documentary',\n",
       " 'Drama',\n",
       " 'Fantasy',\n",
       " 'Film-Noir',\n",
       " 'Horror',\n",
       " 'Musical',\n",
       " 'Mystery',\n",
       " 'Romance',\n",
       " 'Sci-Fi',\n",
       " 'Thriller',\n",
       " 'War',\n",
       " 'Western']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"unknown | Action | Adventure | Animation | Children's | Comedy | Crime | Documentary | Drama | Fantasy | Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi | Thriller | War | Western |\"\n",
    "a.replace(' |','').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 index가 ID가 됨.\n",
    "items = pd.read_csv('https://raw.githubusercontent.com/han942/vscode/refs/heads/main/datafile/Recsys/ml-100k/u.item',encoding='latin-1',\n",
    "                    sep='|',header=None,names=['movieID','title','release_date','video_release_date','URL','unknown',\n",
    " 'Action',\n",
    " 'Adventure',\n",
    " 'Animation',\n",
    " \"Children's\",\n",
    " 'Comedy',\n",
    " 'Crime',\n",
    " 'Documentary',\n",
    " 'Drama',\n",
    " 'Fantasy',\n",
    " 'Film-Noir',\n",
    " 'Horror',\n",
    " 'Musical',\n",
    " 'Mystery',\n",
    " 'Romance',\n",
    " 'Sci-Fi',\n",
    " 'Thriller',\n",
    " 'War',\n",
    " 'Western'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>URL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1678</td>\n",
       "      <td>Mat' i syn (1997)</td>\n",
       "      <td>06-Feb-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Mat%27+i+syn+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1679</td>\n",
       "      <td>B. Monkey (1998)</td>\n",
       "      <td>06-Feb-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?B%2E+Monkey+(...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1680</td>\n",
       "      <td>Sliding Doors (1998)</td>\n",
       "      <td>01-Jan-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Sliding+Doors+(1998)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1681</td>\n",
       "      <td>You So Crazy (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?You%20So%20Cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1682</td>\n",
       "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
       "      <td>08-Mar-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Schrei%20aus%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieID                                      title release_date  \\\n",
       "0           1                           Toy Story (1995)  01-Jan-1995   \n",
       "1           2                           GoldenEye (1995)  01-Jan-1995   \n",
       "2           3                          Four Rooms (1995)  01-Jan-1995   \n",
       "3           4                          Get Shorty (1995)  01-Jan-1995   \n",
       "4           5                             Copycat (1995)  01-Jan-1995   \n",
       "...       ...                                        ...          ...   \n",
       "1677     1678                          Mat' i syn (1997)  06-Feb-1998   \n",
       "1678     1679                           B. Monkey (1998)  06-Feb-1998   \n",
       "1679     1680                       Sliding Doors (1998)  01-Jan-1998   \n",
       "1680     1681                        You So Crazy (1994)  01-Jan-1994   \n",
       "1681     1682  Scream of Stone (Schrei aus Stein) (1991)  08-Mar-1996   \n",
       "\n",
       "      video_release_date                                                URL  \\\n",
       "0                    NaN  http://us.imdb.com/M/title-exact?Toy%20Story%2...   \n",
       "1                    NaN  http://us.imdb.com/M/title-exact?GoldenEye%20(...   \n",
       "2                    NaN  http://us.imdb.com/M/title-exact?Four%20Rooms%...   \n",
       "3                    NaN  http://us.imdb.com/M/title-exact?Get%20Shorty%...   \n",
       "4                    NaN  http://us.imdb.com/M/title-exact?Copycat%20(1995)   \n",
       "...                  ...                                                ...   \n",
       "1677                 NaN  http://us.imdb.com/M/title-exact?Mat%27+i+syn+...   \n",
       "1678                 NaN  http://us.imdb.com/M/title-exact?B%2E+Monkey+(...   \n",
       "1679                 NaN      http://us.imdb.com/Title?Sliding+Doors+(1998)   \n",
       "1680                 NaN  http://us.imdb.com/M/title-exact?You%20So%20Cr...   \n",
       "1681                 NaN  http://us.imdb.com/M/title-exact?Schrei%20aus%...   \n",
       "\n",
       "      unknown  Action  Adventure  Animation  Children's  ...  Fantasy  \\\n",
       "0           0       0          0          1           1  ...        0   \n",
       "1           0       1          1          0           0  ...        0   \n",
       "2           0       0          0          0           0  ...        0   \n",
       "3           0       1          0          0           0  ...        0   \n",
       "4           0       0          0          0           0  ...        0   \n",
       "...       ...     ...        ...        ...         ...  ...      ...   \n",
       "1677        0       0          0          0           0  ...        0   \n",
       "1678        0       0          0          0           0  ...        0   \n",
       "1679        0       0          0          0           0  ...        0   \n",
       "1680        0       0          0          0           0  ...        0   \n",
       "1681        0       0          0          0           0  ...        0   \n",
       "\n",
       "      Film-Noir  Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  War  \\\n",
       "0             0       0        0        0        0       0         0    0   \n",
       "1             0       0        0        0        0       0         1    0   \n",
       "2             0       0        0        0        0       0         1    0   \n",
       "3             0       0        0        0        0       0         0    0   \n",
       "4             0       0        0        0        0       0         1    0   \n",
       "...         ...     ...      ...      ...      ...     ...       ...  ...   \n",
       "1677          0       0        0        0        0       0         0    0   \n",
       "1678          0       0        0        0        1       0         1    0   \n",
       "1679          0       0        0        0        1       0         0    0   \n",
       "1680          0       0        0        0        0       0         0    0   \n",
       "1681          0       0        0        0        0       0         0    0   \n",
       "\n",
       "      Western  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "1677        0  \n",
       "1678        0  \n",
       "1679        0  \n",
       "1680        0  \n",
       "1681        0  \n",
       "\n",
       "[1682 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  age gender  occupation zipcode\n",
       "0       1   24      M  technician   85711\n",
       "1       2   53      F       other   94043\n",
       "2       3   23      M      writer   32067\n",
       "3       4   24      M  technician   43537\n",
       "4       5   33      F       other   15213"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('https://raw.githubusercontent.com/han942/vscode/refs/heads/main/datafile/Recsys/ml-100k/u.user',sep='|',\n",
    "                   names=['userID','age','gender','occupation','zipcode'])\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(data,items.iloc[:,:2],on='movieID')\n",
    "user_movie_matrix = pd.pivot_table(data=df,index='userID',columns='movieID',values='ratings')\n",
    "user_movie_matrix_na = user_movie_matrix.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Based Filtering\n",
    "1. Find Similarity Score btw different users\n",
    "2. For Target User, Set Neighbors ($K$) to refer\n",
    "3. Find the Neighbor Similarity Score\n",
    "4. For Target Items, Predict Ratings for the unknown\n",
    "    - Compution only needs to be done using observed ratings\n",
    "\n",
    "$$prediction(a,p) = \\bar{r_a} + \\frac{\\sum{sim(a,b)}*(r_{b,p}-\\bar{r_b})}{\\sum{|sim(a,b)|}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "user_movie_matrix = pd.pivot_table(data=df,index='userID',columns='movieID',values='ratings')\n",
    "user_movie_matrix_na = user_movie_matrix.fillna(0)\n",
    "\n",
    "user_cos = cosine_similarity(user_movie_matrix_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화1의 rating 평균 3.8783185840707963\n",
      "user1의 rating 평균 3.610294117647059\n"
     ]
    }
   ],
   "source": [
    "print('영화1의 rating 평균',user_movie_matrix[1].mean())\n",
    "print('user1의 rating 평균',user_movie_matrix.loc[1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_matrix_nu = user_movie_matrix_na.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;241m==\u001b[39m user_id:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mprediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnew_p\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 6\u001b[0m, in \u001b[0;36mprediction\u001b[1;34m(user_id, p, b, new_p)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprediction\u001b[39m(user_id,p,b,new_p):\n\u001b[1;32m----> 6\u001b[0m     new_p\u001b[38;5;241m.\u001b[39mloc[user_id,p] \u001b[38;5;241m=\u001b[39m user_movie_matrix_nu[user_id\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msum(user_cos[user_id\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,b\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m (user_movie_matrix_nu[b\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,p\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[43muser_movie_matrix_nu\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mabs(user_cos[user_id\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,b\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\hanan\\miniconda3\\envs\\jupytercode\\Lib\\site-packages\\numpy\\_core\\_methods.py:135\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    132\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    133\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    137\u001b[0m     ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mtrue_divide(\n\u001b[0;32m    138\u001b[0m             ret, rcount, out\u001b[38;5;241m=\u001b[39mret, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#특정 user_id에 대해 전체 참고\n",
    "import numpy as np\n",
    "new_p = user_movie_matrix.copy()\n",
    "\n",
    "def prediction(user_id,p,b,new_p):\n",
    "    new_p.loc[user_id,p] = user_movie_matrix_nu[user_id-1].mean() + np.sum(user_cos[user_id-1,b-1] * (user_movie_matrix_nu[b-1,p-1] - user_movie_matrix_nu[b-1].mean())) / np.sum(np.abs(user_cos[user_id-1,b-1]))\n",
    "user_id = 13\n",
    "for p in range(1,(len(user_movie_matrix.columns.values)+1)):\n",
    "    for b in range(1,(len(user_movie_matrix.index.values)+1)):\n",
    "        if user_movie_matrix_na.loc[user_id,p] == 0:\n",
    "            if b == user_id:\n",
    "                pass\n",
    "            prediction(user_id,p,b,new_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Based CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Factor Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD(MF,Matrix Factorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방법1. 기존의 MF 방법\n",
    "1. 정규분포를 따르는 무작위의 숫자로 구성된 User / Item Latent Matrix P,Q를 구성\n",
    "2. Nan값이 아닌 Rating을 Test $P,Q^T$의 내적값을 predict로 정의\n",
    "3. 두 값 사이의 Error를 구해서 Objective Function에 맞는 Optimization 진행\n",
    "4. 모든 값을 Update 후에 2)~4)의 과정 반복\n",
    "$$\\text{Dimension Guide : } \\\\ R(m*n),P(m*k),Q(n*k) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 112893.7356, RMSE: 1.0625\n",
      "Epoch: 100, Loss: 23209.9920, RMSE: 0.4818\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(not_nan_ind)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,j \u001b[38;5;129;01min\u001b[39;00m not_nan_ind:\n\u001b[1;32m---> 15\u001b[0m     error \u001b[38;5;241m=\u001b[39m R[i,j] \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     P[i,:] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m (error \u001b[38;5;241m*\u001b[39m Q[j,:] \u001b[38;5;241m-\u001b[39m reg_param \u001b[38;5;241m*\u001b[39m P[i,:])\n\u001b[0;32m     17\u001b[0m     Q[j,:] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m (error \u001b[38;5;241m*\u001b[39m P[i,:] \u001b[38;5;241m-\u001b[39m reg_param \u001b[38;5;241m*\u001b[39m Q[j,:])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "R = np.array(user_movie_matrix)\n",
    "n_users,n_items = user_movie_matrix.shape\n",
    "k = 30\n",
    "P = np.random.normal(scale=0.1/k, size=(n_users,k))\n",
    "Q = np.random.normal(scale=0.1/k, size=(n_items,k))\n",
    "epochs = 500\n",
    "lr = 0.03   #높이면 에러 뜨는듯\n",
    "reg_param = 0.02 #0.01~0.1\n",
    "not_nan_ind = [(i,j) for i in range(n_users) for j in range(n_items) if R[i,j]>0]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    np.random.shuffle(not_nan_ind)\n",
    "    for i,j in not_nan_ind:\n",
    "        error = R[i,j] - np.dot(P[i,:],Q[j,:].T)\n",
    "        P[i,:] += lr * (error * Q[j,:] - reg_param * P[i,:])\n",
    "        Q[j,:] += lr * (error * P[i,:] - reg_param * Q[j,:])\n",
    "    if epoch % 100 == 0:\n",
    "        loss = np.sum([((R[i,j]-np.dot(P[i,:],Q[j,:].T))**2) for i,j in not_nan_ind])\n",
    "        rmse = np.sqrt(loss / len(not_nan_ind))\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "R_hat = np.dot(P,Q.T)\n",
    "print(\"\\n예측된 평점 행렬\")\n",
    "print(np.round(R_hat,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방법2. Tensorflow 이용\n",
    "$$ \\text{update rule} \\\\  b_u \\leftarrow b_u + \\eta*(e_{u,i}-\\lambda b_u)\\\\ p_u \\leftarrow p_u+\\eta(e_{u,i}q_i-\\lambda p_u) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss:1372793.3750, RMSE:1171.6626\n",
      "Epoch 100, Loss:nan, RMSE:nan\n",
      "Epoch 200, Loss:nan, RMSE:nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5654\u001b[0m, in \u001b[0;36mgather_nd\u001b[1;34m(params, indices, name, batch_dims)\u001b[0m\n\u001b[0;32m   5651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   5652\u001b[0m   \u001b[38;5;66;03m# TODO(apassos) find a less bad way of detecting resource variables\u001b[39;00m\n\u001b[0;32m   5653\u001b[0m   \u001b[38;5;66;03m# without introducing a circular dependency.\u001b[39;00m\n\u001b[1;32m-> 5654\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_nd\u001b[49m(indices, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   5655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'gather_nd'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 32\u001b[0m         loss,rmse \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     grad \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss,[P,Q])  \n\u001b[0;32m     34\u001b[0m     opt\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grad,[P,Q]))\n",
      "Cell \u001b[1;32mIn[68], line 20\u001b[0m, in \u001b[0;36mloss_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m pred \u001b[38;5;241m=\u001b[39m predict()\n\u001b[0;32m     19\u001b[0m pred_val \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather_nd(pred,obs_ind)\n\u001b[1;32m---> 20\u001b[0m R_val \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43mobs_ind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m error \u001b[38;5;241m=\u001b[39m R_val \u001b[38;5;241m-\u001b[39m pred_val \n\u001b[0;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(tf\u001b[38;5;241m.\u001b[39msquare(error)) \u001b[38;5;66;03m#Loss 함수만 제대로 정의하면, Gradient Descent는 따로 정의할 필요 X\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5664\u001b[0m, in \u001b[0;36mgather_nd_v2\u001b[1;34m(params, indices, batch_dims, name)\u001b[0m\n\u001b[0;32m   5661\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgather_nd\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m   5662\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   5663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgather_nd_v2\u001b[39m(params, indices, batch_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 5664\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgather_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5656\u001b[0m, in \u001b[0;36mgather_nd\u001b[1;34m(params, indices, name, batch_dims)\u001b[0m\n\u001b[0;32m   5654\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m params\u001b[38;5;241m.\u001b[39mgather_nd(indices, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   5655\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m-> 5656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5657\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5658\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m batch_gather_nd(params, indices, batch_dims\u001b[38;5;241m=\u001b[39mbatch_dims, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3963\u001b[0m, in \u001b[0;36mgather_nd\u001b[1;34m(params, indices, name)\u001b[0m\n\u001b[0;32m   3961\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   3962\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgather_nd_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3965\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[0;32m   3966\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3985\u001b[0m, in \u001b[0;36mgather_nd_eager_fallback\u001b[1;34m(params, indices, name, ctx)\u001b[0m\n\u001b[0;32m   3983\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgather_nd_eager_fallback\u001b[39m(params: Annotated[Any, TV_GatherNd_Tparams], indices: Annotated[Any, TV_GatherNd_Tindices], name, ctx) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Annotated[Any, TV_GatherNd_Tparams]:\n\u001b[0;32m   3984\u001b[0m   _attr_Tparams, (params,) \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39margs_to_matching_eager([params], ctx, [])\n\u001b[1;32m-> 3985\u001b[0m   _attr_Tindices, (indices,) \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs_to_matching_eager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3986\u001b[0m   _inputs_flat \u001b[38;5;241m=\u001b[39m [params, indices]\n\u001b[0;32m   3987\u001b[0m   _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTparams\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_Tparams, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTindices\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_Tindices)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:251\u001b[0m, in \u001b[0;36margs_to_matching_eager\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# First see if we can get a valid dtype with the default conversion\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# and see if it matches an allowed dtypes. Some ops like ConcatV2 may\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# not list allowed dtypes, in which case we should skip this.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m allowed_dtypes:\n\u001b[1;32m--> 251\u001b[0m   tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m   \u001b[38;5;66;03m# If we did not match an allowed dtype, try again with the default\u001b[39;00m\n\u001b[0;32m    253\u001b[0m   \u001b[38;5;66;03m# dtype. This could be because we have an empty tensor and thus we\u001b[39;00m\n\u001b[0;32m    254\u001b[0m   \u001b[38;5;66;03m# picked the wrong type.\u001b[39;00m\n\u001b[0;32m    255\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_dtypes:\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1574\u001b[0m, in \u001b[0;36m_autopacking_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_autopacking_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Tensor conversion function that automatically packs arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1574\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m as_ref \u001b[38;5;129;01mor\u001b[39;00m \u001b[43m_should_not_autopack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1576\u001b[0m   inferred_dtype \u001b[38;5;241m=\u001b[39m _get_dtype_from_nested_lists(v)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1568\u001b[0m, in \u001b[0;36m_should_not_autopack\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_should_not_autopack\u001b[39m(v):\n\u001b[0;32m   1563\u001b[0m   \u001b[38;5;66;03m# The condition we really want is\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m   \u001b[38;5;66;03m#    any(isinstance(elem, core.Tensor))\u001b[39;00m\n\u001b[0;32m   1565\u001b[0m   \u001b[38;5;66;03m# but it is >5x slower due to abc.ABCMeta.__instancecheck__.\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m   \u001b[38;5;66;03m# pylint: disable=unidiomatic-typecheck\u001b[39;00m\n\u001b[0;32m   1567\u001b[0m   \u001b[38;5;66;03m# TODO(slebedev): add nest.all?\u001b[39;00m\n\u001b[1;32m-> 1568\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mtype\u001b[39m(elem) \u001b[38;5;129;01min\u001b[39;00m _NON_AUTOPACKABLE_TYPES \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(v))\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\vscode_jupyter\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1568\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_should_not_autopack\u001b[39m(v):\n\u001b[0;32m   1563\u001b[0m   \u001b[38;5;66;03m# The condition we really want is\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m   \u001b[38;5;66;03m#    any(isinstance(elem, core.Tensor))\u001b[39;00m\n\u001b[0;32m   1565\u001b[0m   \u001b[38;5;66;03m# but it is >5x slower due to abc.ABCMeta.__instancecheck__.\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m   \u001b[38;5;66;03m# pylint: disable=unidiomatic-typecheck\u001b[39;00m\n\u001b[0;32m   1567\u001b[0m   \u001b[38;5;66;03m# TODO(slebedev): add nest.all?\u001b[39;00m\n\u001b[1;32m-> 1568\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mtype\u001b[39m(elem) \u001b[38;5;129;01min\u001b[39;00m _NON_AUTOPACKABLE_TYPES \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(v))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "R = np.array(user_movie_matrix,dtype='float32')\n",
    "n_users,n_items = R.shape\n",
    "lr = 0.03\n",
    "K = 20\n",
    "reg_param = 0.02\n",
    "epochs = 500\n",
    "\n",
    "obs_ind = [(i,j) for i in range(n_users) for j in range(n_items) if R[i,j]>0]\n",
    "\n",
    "P = tf.Variable(tf.random.normal([n_users,K],stddev=0.1),dtype=np.float32)  #Latent Feature Extraction (K)\n",
    "Q = tf.Variable(tf.random.normal([n_items,K],stddev=0.1),dtype=np.float32)\n",
    "\n",
    "def predict():\n",
    "    return tf.matmul(P,Q,transpose_b=True)\n",
    "def loss_fn():\n",
    "    pred = predict()\n",
    "    pred_val = tf.gather_nd(pred,obs_ind)\n",
    "    R_val = tf.gather_nd(R,obs_ind)\n",
    "    \n",
    "    error = R_val - pred_val \n",
    "    loss = tf.reduce_sum(tf.square(error)) #Loss 함수만 제대로 정의하면, Gradient Descent는 따로 정의할 필요 X\n",
    "    reg_loss = reg_param * (tf.nn.l2_loss(P)+tf.nn.l2_loss(Q))\n",
    "    \n",
    "    return loss + reg_loss\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn()\n",
    "    rmse = tf.sqrt(tf.square(error) / len(error))\n",
    "    grad = tape.gradient(loss,[P,Q])  \n",
    "    opt.apply_gradients(zip(grad,[P,Q]))\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss:{loss.numpy():.4f}, RMSE:{rmse.numpy():.4f}\")\n",
    "\n",
    "R_pred = predict().numpy()\n",
    "print(\"\\nPredicted R:\")\n",
    "print(np.round(R_pred,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
